{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 20,10\n",
    "import numpy as np\n",
    "import glob\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/racheldilley/Documents/Metis/git_repos/mta-project-1/CSVs\n"
     ]
    }
   ],
   "source": [
    "cd CSVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C/A</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>SCP</th>\n",
       "      <th>STATION</th>\n",
       "      <th>LINENAME</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DESC</th>\n",
       "      <th>ENTRIES</th>\n",
       "      <th>EXITS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>05/11/2019</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>7053483</td>\n",
       "      <td>2390505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>05/11/2019</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>7053511</td>\n",
       "      <td>2390508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>05/11/2019</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>7053534</td>\n",
       "      <td>2390536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>05/11/2019</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>7053618</td>\n",
       "      <td>2390596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>05/11/2019</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>7053841</td>\n",
       "      <td>2390655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206852</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>R</td>\n",
       "      <td>RIT</td>\n",
       "      <td>05/03/2019</td>\n",
       "      <td>05:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>5554</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206853</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>R</td>\n",
       "      <td>RIT</td>\n",
       "      <td>05/03/2019</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>5554</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206854</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>R</td>\n",
       "      <td>RIT</td>\n",
       "      <td>05/03/2019</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>5554</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206855</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>R</td>\n",
       "      <td>RIT</td>\n",
       "      <td>05/03/2019</td>\n",
       "      <td>17:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>5554</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206856</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>R</td>\n",
       "      <td>RIT</td>\n",
       "      <td>05/03/2019</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>5554</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2250808 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          C/A  UNIT       SCP        STATION LINENAME DIVISION        DATE  \\\n",
       "0        A002  R051  02-00-00          59 ST  NQR456W      BMT  05/11/2019   \n",
       "1        A002  R051  02-00-00          59 ST  NQR456W      BMT  05/11/2019   \n",
       "2        A002  R051  02-00-00          59 ST  NQR456W      BMT  05/11/2019   \n",
       "3        A002  R051  02-00-00          59 ST  NQR456W      BMT  05/11/2019   \n",
       "4        A002  R051  02-00-00          59 ST  NQR456W      BMT  05/11/2019   \n",
       "...       ...   ...       ...            ...      ...      ...         ...   \n",
       "206852  TRAM2  R469  00-05-01  RIT-ROOSEVELT        R      RIT  05/03/2019   \n",
       "206853  TRAM2  R469  00-05-01  RIT-ROOSEVELT        R      RIT  05/03/2019   \n",
       "206854  TRAM2  R469  00-05-01  RIT-ROOSEVELT        R      RIT  05/03/2019   \n",
       "206855  TRAM2  R469  00-05-01  RIT-ROOSEVELT        R      RIT  05/03/2019   \n",
       "206856  TRAM2  R469  00-05-01  RIT-ROOSEVELT        R      RIT  05/03/2019   \n",
       "\n",
       "            TIME     DESC  ENTRIES  \\\n",
       "0       00:00:00  REGULAR  7053483   \n",
       "1       04:00:00  REGULAR  7053511   \n",
       "2       08:00:00  REGULAR  7053534   \n",
       "3       12:00:00  REGULAR  7053618   \n",
       "4       16:00:00  REGULAR  7053841   \n",
       "...          ...      ...      ...   \n",
       "206852  05:00:00  REGULAR     5554   \n",
       "206853  09:00:00  REGULAR     5554   \n",
       "206854  13:00:00  REGULAR     5554   \n",
       "206855  17:00:00  REGULAR     5554   \n",
       "206856  21:00:00  REGULAR     5554   \n",
       "\n",
       "        EXITS                                                                 \n",
       "0                                                 2390505                     \n",
       "1                                                 2390508                     \n",
       "2                                                 2390536                     \n",
       "3                                                 2390596                     \n",
       "4                                                 2390655                     \n",
       "...                                                   ...                     \n",
       "206852                                                376                     \n",
       "206853                                                376                     \n",
       "206854                                                376                     \n",
       "206855                                                376                     \n",
       "206856                                                376                     \n",
       "\n",
       "[2250808 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extension = 'txt'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "\n",
    "#combine all files in the list\n",
    "data = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove spaces from column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = data.columns.str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add Date_Time column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Date_Time'] = pd.to_datetime(data['DATE'], cache=True) + pd.to_timedelta(data['TIME'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Turnstile (Combining SCP,C/A, Station and Unit) and Weekday column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Turnstile'] = data['C/A'] + data['UNIT'] + data['SCP'] + data['STATION']\n",
    "data['DATE'] = pd.to_datetime(data['DATE'], cache=True)\n",
    "data['Week_Day'] = data['DATE'].dt.day_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find total traffic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add shifted columns to show previous entries and exits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All turnstiles have cumulative counts, previous data needs to be subtraced from current data \n",
    "#to find total entries/exits\n",
    "grouped_time=data\n",
    "grouped_time[\"PREV_TIME\"] = data.groupby([\"Turnstile\"]).TIME.shift(1)\n",
    "grouped_time[\"PREV_EXITS\"] = data.groupby([\"Turnstile\"]).EXITS.shift(1)\n",
    "grouped_time[\"PREV_ENTRIES\"] = data.groupby([\"Turnstile\"]).ENTRIES.shift(1)\n",
    "#grouped_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop first row of each turnstile b/c of shift down\n",
    "grouped_time.dropna(subset=[\"PREV_ENTRIES\"], axis=0, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove counter errors from total entries/exits that occur from counters resetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_counts_exits(row, max_counter):\n",
    "    counter_ex = row[\"EXITS\"] - row[\"PREV_EXITS\"]\n",
    "    if counter_ex < 0:\n",
    "        # Maybe counter is reversed?\n",
    "        counter_ex = -counter_ex\n",
    "    if counter_ex > max_counter:\n",
    "        # Maybe counter was reset to 0? \n",
    "        #print(row[\"EXITS\"], row[\"PREV_EXITS\"])\n",
    "        counter = min(row[\"EXITS\"], row[\"PREV_EXITS\"])\n",
    "    if counter_ex > max_counter:\n",
    "        # Check it again to make sure we're not still giving a counter that's too big\n",
    "        return 0\n",
    "    return counter_ex\n",
    "\n",
    "def get_daily_counts_entries(row, max_counter):\n",
    "    counter_ent = row[\"ENTRIES\"] - row[\"PREV_ENTRIES\"]\n",
    "    if counter_ent < 0:\n",
    "        # Maybe counter is reversed?\n",
    "        counter_ent = -counter_ent\n",
    "    if counter_ent > max_counter:\n",
    "        # Maybe counter was reset to 0? \n",
    "        #print(row[\"ENTRIES\"], row[\"PREV_ENTRIES\"])\n",
    "        counter = min(row[\"ENTRIES\"], row[\"PREV_ENTRIES\"])\n",
    "    if counter_ent > max_counter:\n",
    "        # Check it again to make sure we're not still giving a counter that's too big\n",
    "        return 0\n",
    "    return counter_ent\n",
    "\n",
    "\n",
    "# If counter is > 1Million, then the counter might have been reset.  \n",
    "# Just set it to zero as different counters have different cycle limits\n",
    "# It'd probably be a good idea to use a number even significantly smaller than 1 million as the limit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_time[\"TOTAL_ENTRIES\"] = grouped_time.apply(get_daily_counts_entries, axis=1, max_counter=1000000)\n",
    "grouped_time[\"TOTAL_EXITS\"] = grouped_time.apply(get_daily_counts_exits, axis=1, max_counter=1000000)\n",
    "#grouped_time[\"TOTAL_EXITS\"] = grouped_time.apply(get_daily_counts, axis=1, max_counter=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C/A</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>SCP</th>\n",
       "      <th>STATION</th>\n",
       "      <th>LINENAME</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DESC</th>\n",
       "      <th>ENTRIES</th>\n",
       "      <th>...</th>\n",
       "      <th>Date_Time</th>\n",
       "      <th>Turnstile</th>\n",
       "      <th>Week_Day</th>\n",
       "      <th>PREV_TIME</th>\n",
       "      <th>PREV_EXITS</th>\n",
       "      <th>PREV_ENTRIES</th>\n",
       "      <th>(TOTAL_ENTRIES, TOTAL_EXITS)</th>\n",
       "      <th>TOTAL_ENTRIES</th>\n",
       "      <th>TOTAL_EXITS</th>\n",
       "      <th>TOTAL_TRAFFIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2019-05-11</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>7053511</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-05-11 04:00:00</td>\n",
       "      <td>A002R05102-00-0059 ST</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>2390505.0</td>\n",
       "      <td>7053483.0</td>\n",
       "      <td>(28.0, 3.0)</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2019-05-11</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>7053534</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-05-11 08:00:00</td>\n",
       "      <td>A002R05102-00-0059 ST</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>2390508.0</td>\n",
       "      <td>7053511.0</td>\n",
       "      <td>(23.0, 28.0)</td>\n",
       "      <td>23.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2019-05-11</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>7053618</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-05-11 12:00:00</td>\n",
       "      <td>A002R05102-00-0059 ST</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>2390536.0</td>\n",
       "      <td>7053534.0</td>\n",
       "      <td>(84.0, 60.0)</td>\n",
       "      <td>84.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2019-05-11</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>7053841</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-05-11 16:00:00</td>\n",
       "      <td>A002R05102-00-0059 ST</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>2390596.0</td>\n",
       "      <td>7053618.0</td>\n",
       "      <td>(223.0, 59.0)</td>\n",
       "      <td>223.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>282.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2019-05-11</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>7054133</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-05-11 20:00:00</td>\n",
       "      <td>A002R05102-00-0059 ST</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>2390655.0</td>\n",
       "      <td>7053841.0</td>\n",
       "      <td>(292.0, 47.0)</td>\n",
       "      <td>292.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>339.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    C/A  UNIT       SCP STATION LINENAME DIVISION       DATE      TIME  \\\n",
       "1  A002  R051  02-00-00   59 ST  NQR456W      BMT 2019-05-11  04:00:00   \n",
       "2  A002  R051  02-00-00   59 ST  NQR456W      BMT 2019-05-11  08:00:00   \n",
       "3  A002  R051  02-00-00   59 ST  NQR456W      BMT 2019-05-11  12:00:00   \n",
       "4  A002  R051  02-00-00   59 ST  NQR456W      BMT 2019-05-11  16:00:00   \n",
       "5  A002  R051  02-00-00   59 ST  NQR456W      BMT 2019-05-11  20:00:00   \n",
       "\n",
       "      DESC  ENTRIES  ...           Date_Time              Turnstile  Week_Day  \\\n",
       "1  REGULAR  7053511  ... 2019-05-11 04:00:00  A002R05102-00-0059 ST  Saturday   \n",
       "2  REGULAR  7053534  ... 2019-05-11 08:00:00  A002R05102-00-0059 ST  Saturday   \n",
       "3  REGULAR  7053618  ... 2019-05-11 12:00:00  A002R05102-00-0059 ST  Saturday   \n",
       "4  REGULAR  7053841  ... 2019-05-11 16:00:00  A002R05102-00-0059 ST  Saturday   \n",
       "5  REGULAR  7054133  ... 2019-05-11 20:00:00  A002R05102-00-0059 ST  Saturday   \n",
       "\n",
       "  PREV_TIME PREV_EXITS  PREV_ENTRIES  (TOTAL_ENTRIES, TOTAL_EXITS)  \\\n",
       "1  00:00:00  2390505.0     7053483.0                   (28.0, 3.0)   \n",
       "2  04:00:00  2390508.0     7053511.0                  (23.0, 28.0)   \n",
       "3  08:00:00  2390536.0     7053534.0                  (84.0, 60.0)   \n",
       "4  12:00:00  2390596.0     7053618.0                 (223.0, 59.0)   \n",
       "5  16:00:00  2390655.0     7053841.0                 (292.0, 47.0)   \n",
       "\n",
       "  TOTAL_ENTRIES  TOTAL_EXITS  TOTAL_TRAFFIC  \n",
       "1          28.0          3.0           31.0  \n",
       "2          23.0         28.0           51.0  \n",
       "3          84.0         60.0          144.0  \n",
       "4         223.0         59.0          282.0  \n",
       "5         292.0         47.0          339.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_time[\"TOTAL_TRAFFIC\"] = grouped_time[\"TOTAL_EXITS\"] + grouped_time[\"TOTAL_ENTRIES\"]\n",
    "grouped_time.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove total traffic outliers that are 3 sigmas from mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_time = grouped_time[(np.abs(stats.zscore(grouped_time['TOTAL_TRAFFIC'])) < 3)] #filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop uneeded columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_time.drop(['C/A','UNIT','SCP','LINENAME', 'ENTRIES', 'EXITS', 'PREV_TIME', 'PREV_ENTRIES', 'PREV_EXITS'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouped_day = data.groupby(['DATE','Turnstile','STATION'], as_index=False).agg({'ENTRIES': ['min', 'max'], 'EXITS': ['min', 'max']})\n",
    "#grouped = data.groupby(['STATION','DATE']).agg({'ENTRIES': ['min', 'max'], 'EXITS': ['min', 'max']})\n",
    "#grouped = grouped.set_index('STATION')\n",
    "#grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouped_day.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouped.columns = [ 'Station', 'Date', 'ENTRIES_MIN', 'ENTRIES_MAX', 'EXITS_MIN', 'EXITS_MAX']\n",
    "grouped_day.columns = [ 'Date', 'Turnstile', 'Station','ENTRIES_MIN', 'ENTRIES_MAX', 'EXITS_MIN', 'EXITS_MAX']\n",
    "#grouped.columns = ['ENTRIES_MIN', 'ENTRIES_MAX', 'EXITS_MIN', 'EXITS_MAX']\n",
    "#grouped.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find total entries exits, and traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_day['Total_Entries'] = grouped_day['ENTRIES_MAX'] - grouped_day['ENTRIES_MIN']\n",
    "grouped_day['Total_Exits'] = grouped_day['EXITS_MAX'] - grouped_day['EXITS_MIN']\n",
    "grouped_day['Total_Traffic'] = grouped_day['Total_Exits'] + grouped_day['Total_Entries']\n",
    "#grouped_day.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouped_day.drop(['ENTRIES_MIN','ENTRIES_MAX','EXITS_MIN','EXITS_MAX', 'Total_Entries', 'Total_Exits', ], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Outlier data from Total_traffic column (Removing anything outside 3 sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_day = grouped_day[(np.abs(stats.zscore(grouped_day['Total_Traffic'])) < 3)] #filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouped_time[grouped_time[\"ENTRIES\"] < grouped_time[\"PREV_ENTRIES\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouped_time = data.sort_values(['Date_Time']).groupby(['Turnstile','STATION','DIVISION','Date_Time'],as_index = False).agg({'ENTRIES': ['diff'], 'EXITS': ['diff']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouped_time = data\n",
    "#grouped_time.sort_values(['Turnstile','Date_Time'],inplace = True)\n",
    "#grouped_time.head(5)\n",
    "#entry_vals = grouped_time['ENTRIES'].values\n",
    "#exit_vals = grouped_time['EXITS'].values\n",
    "#len(entry)\n",
    "#len (entry_vals[:-1])\n",
    "#len (entry_vals[1:])\n",
    "#diffs_entry = entry_vals[1:] - entry_vals[:-1]\n",
    "#diffs_exit = exit_vals[1:] - exit_vals[:-1]\n",
    "#diffs_entry = np.append(diffs_entry,0)\n",
    "#diffs_exit = np.append(diffs_exit,0)\n",
    "#grouped_time['diffs_entry'] = grouped_time.groupby(['Turnstile'])['ENTRIES'].diff()\n",
    "#grouped_time['diffs_exit'] = grouped_time.groupby(['Turnstile'])['EXITS'].diff()\n",
    "#mask = !((grouped_time['diffs_entry'] == 0) && (grouped_time['diffs_exit'] == 0))\n",
    "#mask =   grouped_time['diffs_entry'] == 0\n",
    "#grouped_time = grouped_time[grouped_time['diffs_entry'] ]\n",
    "#grouped_time['diffs_entry'] = grouped_time.rolling_apply(data['ENTRIES'], 2, lambda x: x[1] - x[0])\n",
    "#grouped_time['diffs_exit'] = grouped_time.rolling_apply(data['EXITS'], 2, lambda x: x[1] - x[0])\n",
    "#grouped_time.head()\n",
    "#mask\n",
    "#grouped_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entry_vals = grouped_time['ENTRIES'].values\n",
    "#entry_vals[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouped_time = data.groupby(['STATION','TIME'], as_index=False).agg({'ENTRIES': ['diff'], 'EXITS': ['diff']})\n",
    "#grouped_time.head()\n",
    "#grouped_time.columns = ['Station', 'Time', 'ENTRIES_MIN', 'ENTRIES_MAX', 'EXITS_MIN', 'EXITS_MAX']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_time['Total_Entries'] = grouped_time['ENTRIES_MAX'] - grouped_time['ENTRIES_MIN']\n",
    "grouped_time['Total_Exits'] = grouped_time['EXITS_MAX'] - grouped_time['EXITS_MIN']\n",
    "grouped_time['Total_Traffic'] = grouped_time['Total_Exits'] + grouped_time['Total_Entries']\n",
    "grouped_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_time.drop(['ENTRIES_MIN','ENTRIES_MAX','EXITS_MIN','EXITS_MAX', 'Total_Entries', 'Total_Exits', ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding top 10 visited stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grouped_day' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-8bc3c35ef6ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTotal_ridership\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrouped_day\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Station'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTotal_Traffic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'grouped_day' is not defined"
     ]
    }
   ],
   "source": [
    "Total_ridership = grouped_day.groupby(['Station']).Total_Traffic.sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_ridership.sort_values(by=['Total_Traffic'],inplace = True, ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Row_list =[] \n",
    "indices = []\n",
    "  \n",
    "# Iterate over each row \n",
    "for index, rows in Total_ridership[:10].iterrows(): \n",
    "    # Create list for the current row \n",
    "#    my_list =[rows.STATION, rows.Total_Traffic] \n",
    "    my_list =rows.Total_Traffic \n",
    "    station_list = rows.Station\n",
    "    # append the list to the final list \n",
    "    Row_list.append(my_list) \n",
    "    indices.append(station_list)\n",
    "Total_ridership.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylim(10000000,21000000)\n",
    "plt.xlabel(\"Station\")\n",
    "plt.ylabel(\"Total Traffic\")\n",
    "plt.title(\"Total traffic for the period for top 10 busiest stations\")\n",
    "plt.bar(indices, Row_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 Busy Stations, We will focus on top5 of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find high traffic days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_Weekly_ridership = grouped_day.groupby(['Week_Day']).Total_Traffic.sum().reset_index()\n",
    "#Total_Weekly_ridership = grouped_day.groupby(['Week_Day']).Total_Traffic.mean().reset_index()\n",
    "Total_Weekly_ridership.sort_values(by=['Total_Traffic'],inplace = True, ascending = False)\n",
    "Total_Weekly_ridership.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.ylim(1610000000000,1620000000000)\n",
    "plt.ylim(40000000,140000000)\n",
    "plt.bar(Total_Weekly_ridership['Week_Day'], Total_Weekly_ridership['Total_Traffic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this it seems like weekends see much less traffic compared to weekdays. So WWTF should focus more on weekdays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Top5 = Total_ridership['Station'][0:5].tolist()\n",
    "Top5_stations = grouped_day[grouped_day['Station'].isin(Top5)]\n",
    "Top5_station_weekly = Top5_stations.groupby(['Station','Week_Day']).Total_Traffic.sum().reset_index()\n",
    "Top5_station_Daily = Top5_stations.groupby(['Station','Date']).Total_Traffic.sum().reset_index()\n",
    "#Top5_station_weekly = Top5_stations.groupby(['Station','Week_Day']).Total_Traffic.mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weekly Plot for Top5 stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for stations in Top5:\n",
    "    station = Top5_station_weekly[Top5_station_weekly['Station'] == stations]\n",
    "#    print(station)\n",
    "    plt.plot(station['Week_Day'],station['Total_Traffic'],label = stations)\n",
    "#plt.ylim(32500000000,40700000000)\n",
    "#plt.ylim(400000000,405000000)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the plot seems like top5 stations are also showing a dip on weekends, but PATH NEW WTC station is oblitrating seeing the trend properly. This needs to be investigated further. Also, to see the trend for rest of the station we will do another plot removing the data for PATH NEW WTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stations in Top5:\n",
    "    if stations != \"PATH NEW WTC\" :\n",
    "        station = Top5_station_weekly[Top5_station_weekly['Station'] == stations]\n",
    "#    print(station)\n",
    "        plt.plot(station['Week_Day'],station['Total_Traffic'],label = stations)\n",
    "#plt.ylim(32500000000,40700000000)\n",
    "#plt.ylim(400000000,405000000)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is also showing the dip in weekend more clearly. But GRD CNTRL-42 ST shows peak on thursday - which needs to be investigated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stations in Top5:\n",
    "    station = Top5_station_Daily[Top5_station_Daily['Station'] == stations]\n",
    "#    print(station)\n",
    "    plt.plot(station['Date'],station['Total_Traffic'],label = stations)\n",
    "#plt.ylim(32500000000,40700000000)\n",
    "#plt.ylim(400000000,405000000)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot is also showing some abnormal values for some of the days for PATH NEW WTC. Two of these dates are looking on thursdays. We will look at rest of the stations removing PATH NEW WTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stations in Top5:\n",
    "    if stations != \"PATH NEW WTC\" :\n",
    "        station = Top5_station_Daily[Top5_station_Daily['Station'] == stations]\n",
    "#    print(station)\n",
    "        plt.plot(station['Date'],station['Total_Traffic'],label = stations)\n",
    "#plt.ylim(32500000000,40700000000)\n",
    "#plt.ylim(400000000,405000000)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot also seems to have some outliers. But In general trend is clear Traffic takes a dip on weekends and remains kind of static on weekdays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find peak hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find high traffic areas for games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find top stations in each area code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_data = pd.read_csv('http://web.mta.info/developers/data/nyct/subway/Stations.csv')\n",
    "print(loc_data.Borough.unique())\n",
    "loc_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
